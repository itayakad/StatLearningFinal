{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports + Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"yiyanghkust/finbert-tone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Stock + News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(ticker, start, end, api_key):\n",
    "    url = (\n",
    "        f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY\"\n",
    "        f\"&symbol={ticker}&outputsize=compact&apikey={api_key}\"\n",
    "    )\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if \"Time Series (Daily)\" not in data:\n",
    "        print(f\"[!] Alpha Vantage error: {data}\")\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data[\"Time Series (Daily)\"], orient=\"index\", dtype=float)\n",
    "    df = df.rename(columns={\n",
    "        \"1. open\": \"Open\",\n",
    "        \"2. high\": \"High\",\n",
    "        \"3. low\": \"Low\",\n",
    "        \"4. close\": \"Close\",\n",
    "        \"5. volume\": \"Volume\"\n",
    "    })\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    # Filter to match date range\n",
    "    df = df[(df.index.date >= start) & (df.index.date <= end)]\n",
    "    df[\"daily_return\"] = df[\"Close\"].pct_change()\n",
    "    df[\"volume_change\"] = df[\"Volume\"].pct_change()\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_news_articles(query, from_date, to_date, api_key=\"NEWS_API_KEY\"):\n",
    "    url = (\n",
    "        f'https://newsapi.org/v2/everything?q={query}&from={from_date}&to={to_date}'\n",
    "        f'&language=en&sortBy=publishedAt&pageSize=100&apiKey={api_key}'\n",
    "    )\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return data.get('articles', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(articles):\n",
    "    records = []\n",
    "\n",
    "    for article in articles:\n",
    "        text = (article.get(\"title\", \"\") or \"\") + \" \" + (article.get(\"description\", \"\") or \"\")\n",
    "        if not text.strip():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            result = sentiment_pipeline(text[:512])[0]  # Truncate to 512 tokens max\n",
    "            label = result[\"label\"]\n",
    "            score = {\"Positive\": 1, \"Neutral\": 0, \"Negative\": -1}.get(label, 0)\n",
    "            date = article['publishedAt'][:10]\n",
    "            records.append((date, score))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping article due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(records, columns=[\"date\", \"sentiment\"])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    return df.groupby(\"date\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_label(stock_df, sentiment_df):\n",
    "    df = stock_df.merge(sentiment_df, how='left', left_index=True, right_index=True)\n",
    "    df['sentiment'] = df['sentiment'].fillna(0)\n",
    "    df['target'] = (df['Close'].shift(-1) > df['Close']).astype(int)\n",
    "    return df.dropna()\n",
    "\n",
    "def train_and_evaluate(df):\n",
    "    features = ['sentiment', 'daily_return', 'volume_change']\n",
    "    X = df[features]\n",
    "    y = df['target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(classification_report(y_test, preds))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.53      0.53      0.53        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/4xmgrfc51wbdcr99s78myn_w0000gn/T/ipykernel_25694/1565271532.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sentiment'] = df['sentiment'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "end_date = datetime.today().date() - timedelta(days=1)\n",
    "start_date = end_date - timedelta(days=100)\n",
    "\n",
    "start_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "end_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "ticker = \"AAPL\"\n",
    "\n",
    "# Run\n",
    "stock_df = get_stock_data(ticker, start_date, end_date, api_key=\"3MOQ4Q8MBBMQ5KCD\")\n",
    "news_articles = get_news_articles(ticker, start_date, end_date, api_key=\"90d80862968d439ab1f7cb56d1c054a3\")\n",
    "sentiment_df = analyze_sentiment(news_articles)\n",
    "merged_df = merge_and_label(stock_df, sentiment_df)\n",
    "model = train_and_evaluate(merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
